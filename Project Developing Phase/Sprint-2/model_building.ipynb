{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6CLQaE8KDGT"
      },
      "source": [
        "##Project name - Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAIn-mx8KN6p"
      },
      "source": [
        "##Team Id - PNT2022TMID39097"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4vjDLCsKWdS"
      },
      "source": [
        "##Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For body"
      ],
      "metadata": {
        "id": "hW27mPkFCBwe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhYRUYFLFY_C"
      },
      "source": [
        "##1.Importing The Model Building Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8SNIiFRkFet4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vvTY0qYG5KA"
      },
      "source": [
        "##2.Loading The Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VueWAALCLP2D"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ibm project files/Car damage/body/training'\n",
        "valid_path = '/content/drive/MyDrive/ibm project files/Car damage/body/validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlRcRajfHXAV",
        "outputId": "525aba64-ca4d-47b3-bb2a-ca4494fb8deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnpZrV9rPyc1"
      },
      "source": [
        "##3.Adding Flatten Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ebIkuWhCP1tq"
      },
      "outputs": [],
      "source": [
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fXXOXt1iP9NG"
      },
      "outputs": [],
      "source": [
        "folders = glob('/content/drive/MyDrive/ibm project files/Car damage/body/training/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rY-Da3gQxwY",
        "outputId": "33af9c72-eaf1-48a6-8902-67ed4d35c3a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/ibm project files/Car damage/body/training/02-side',\n",
              " '/content/drive/MyDrive/ibm project files/Car damage/body/training/00-front',\n",
              " '/content/drive/MyDrive/ibm project files/Car damage/body/training/01-rear']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AizEUOnGRioa"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(vgg16.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_WcWCPoRwme",
        "outputId": "c3d3d160-1b46-4e1c-d652-c7fb7bf29a97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(folders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f10aM_e1SchY"
      },
      "source": [
        "##4.Adding Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nCIDSJ7aSfr4"
      },
      "outputs": [],
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S_dB3yiS9b5"
      },
      "source": [
        "##5.Creating A model Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I8pGDpEmTCvC"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=vgg16.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2OOZgfMTEqV",
        "outputId": "7a8040b9-93db-41bb-9358-ad94489b6cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 75267     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,789,955\n",
            "Trainable params: 75,267\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh0s4ISiTejI"
      },
      "source": [
        "##6.Configure The Learning Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6gWv3UvbTgUU"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi20IItcT81l"
      },
      "source": [
        "##7.Train The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZTnPDLLTghzu"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.1,zoom_range=0.1,horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9sGSPO6Xi2ga"
      },
      "outputs": [],
      "source": [
        "trainPath = '/content/drive/MyDrive/ibm project files/Car damage/body/training'\n",
        "testPath = '/content/drive/MyDrive/ibm project files/Car damage/body/validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpUMQ2SVT_Mp",
        "outputId": "5008b1dc-2280-42d7-97f4-fbdf6bad9e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 979 images belonging to 3 classes.\n",
            "Found 171 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory(trainPath,target_size=(244,244),batch_size=10,class_mode='categorical')\n",
        "test_set = train_datagen.flow_from_directory(testPath,target_size=(244,244),batch_size=10,class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l43Bp3d6j0as",
        "outputId": "2bd01716-8b60-4a13-94f4-445d1235e892"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'00-front': 0, '01-rear': 1, '02-side': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "training_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FUx612hlHYC",
        "outputId": "6cf292b2-3da5-4dd1-8ded-e85192c0bc81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "97/97 [==============================] - 650s 7s/step - loss: 1.2234 - accuracy: 0.5284 - val_loss: 1.0827 - val_accuracy: 0.6118\n",
            "Epoch 2/25\n",
            "97/97 [==============================] - 656s 7s/step - loss: 0.6422 - accuracy: 0.7678 - val_loss: 1.8828 - val_accuracy: 0.5647\n",
            "Epoch 3/25\n",
            "97/97 [==============================] - 655s 7s/step - loss: 0.6094 - accuracy: 0.7843 - val_loss: 0.9752 - val_accuracy: 0.6529\n",
            "Epoch 4/25\n",
            "97/97 [==============================] - 660s 7s/step - loss: 0.4152 - accuracy: 0.8338 - val_loss: 1.1492 - val_accuracy: 0.6294\n",
            "Epoch 5/25\n",
            "97/97 [==============================] - 651s 7s/step - loss: 0.2969 - accuracy: 0.8854 - val_loss: 0.8088 - val_accuracy: 0.6588\n",
            "Epoch 6/25\n",
            "97/97 [==============================] - 650s 7s/step - loss: 0.2217 - accuracy: 0.9205 - val_loss: 1.0630 - val_accuracy: 0.6588\n",
            "Epoch 7/25\n",
            "97/97 [==============================] - 649s 7s/step - loss: 0.1782 - accuracy: 0.9412 - val_loss: 0.9224 - val_accuracy: 0.6588\n",
            "Epoch 8/25\n",
            "97/97 [==============================] - 648s 7s/step - loss: 0.1546 - accuracy: 0.9525 - val_loss: 0.9935 - val_accuracy: 0.6471\n",
            "Epoch 9/25\n",
            "97/97 [==============================] - 644s 7s/step - loss: 0.0915 - accuracy: 0.9752 - val_loss: 0.9546 - val_accuracy: 0.6941\n",
            "Epoch 10/25\n",
            "97/97 [==============================] - 642s 7s/step - loss: 0.1482 - accuracy: 0.9484 - val_loss: 1.0096 - val_accuracy: 0.6706\n",
            "Epoch 11/25\n",
            "97/97 [==============================] - 646s 7s/step - loss: 0.1008 - accuracy: 0.9701 - val_loss: 1.2118 - val_accuracy: 0.6294\n",
            "Epoch 12/25\n",
            "97/97 [==============================] - 648s 7s/step - loss: 0.1229 - accuracy: 0.9536 - val_loss: 1.1114 - val_accuracy: 0.6353\n",
            "Epoch 13/25\n",
            "97/97 [==============================] - 643s 7s/step - loss: 0.0880 - accuracy: 0.9752 - val_loss: 1.0526 - val_accuracy: 0.6471\n",
            "Epoch 14/25\n",
            "97/97 [==============================] - 646s 7s/step - loss: 0.0683 - accuracy: 0.9835 - val_loss: 1.2274 - val_accuracy: 0.7000\n",
            "Epoch 15/25\n",
            "97/97 [==============================] - 641s 7s/step - loss: 0.0896 - accuracy: 0.9845 - val_loss: 1.0969 - val_accuracy: 0.6824\n",
            "Epoch 16/25\n",
            "97/97 [==============================] - 639s 7s/step - loss: 0.1014 - accuracy: 0.9773 - val_loss: 1.0355 - val_accuracy: 0.7000\n",
            "Epoch 17/25\n",
            "97/97 [==============================] - 634s 7s/step - loss: 0.0738 - accuracy: 0.9876 - val_loss: 1.0759 - val_accuracy: 0.7059\n",
            "Epoch 18/25\n",
            "97/97 [==============================] - 620s 6s/step - loss: 0.0491 - accuracy: 0.9897 - val_loss: 1.1174 - val_accuracy: 0.7176\n",
            "Epoch 19/25\n",
            "97/97 [==============================] - 620s 6s/step - loss: 0.0457 - accuracy: 0.9917 - val_loss: 1.1022 - val_accuracy: 0.7235\n",
            "Epoch 20/25\n",
            "97/97 [==============================] - 621s 6s/step - loss: 0.0646 - accuracy: 0.9886 - val_loss: 1.2654 - val_accuracy: 0.6529\n",
            "Epoch 21/25\n",
            "97/97 [==============================] - 620s 6s/step - loss: 0.0805 - accuracy: 0.9711 - val_loss: 1.2195 - val_accuracy: 0.6882\n",
            "Epoch 22/25\n",
            "97/97 [==============================] - 621s 6s/step - loss: 0.1156 - accuracy: 0.9721 - val_loss: 1.5249 - val_accuracy: 0.6294\n",
            "Epoch 23/25\n",
            "97/97 [==============================] - 620s 6s/step - loss: 0.0555 - accuracy: 0.9886 - val_loss: 1.3490 - val_accuracy: 0.6882\n",
            "Epoch 24/25\n",
            "97/97 [==============================] - 621s 6s/step - loss: 0.0423 - accuracy: 0.9917 - val_loss: 1.1550 - val_accuracy: 0.6824\n",
            "Epoch 25/25\n",
            "97/97 [==============================] - 621s 6s/step - loss: 0.0832 - accuracy: 0.9835 - val_loss: 1.1483 - val_accuracy: 0.6941\n"
          ]
        }
      ],
      "source": [
        "r = model.fit_generator(\n",
        "    training_set,\n",
        "    validation_data = test_set,\n",
        "    epochs = 25,\n",
        "    steps_per_epoch=979//10,\n",
        "    validation_steps = 171//10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8.Save The Model"
      ],
      "metadata": {
        "id": "X78caxjF53UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n"
      ],
      "metadata": {
        "id": "gvl7EbRM9XS3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/damage vehicle/Model/body.h5')"
      ],
      "metadata": {
        "id": "sQdfqTh6Qva6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9.Test The Model"
      ],
      "metadata": {
        "id": "FBYulTYA99fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "PTmckQLK-GDx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/damage vehicle/Model/body.h5')"
      ],
      "metadata": {
        "id": "KIIycBKG-OAJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "  img = cv2.resize(frame,(224,224))\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if(np.max(img)>1):\n",
        "    img = img/255.0\n",
        "  img = np.array([img])\n",
        "  prediction = model.predict(img)\n",
        "  label = [\"front\",\"rear\",\"side\"]\n",
        "  preds = label[np.argmax(prediction)]\n",
        "  return preds"
      ],
      "metadata": {
        "id": "PUqRzuhY-RiX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "uoW22FUX-dce"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"/content/drive/MyDrive/ibm project files/Car damage/body/training/00-front/0002.JPEG\"\n",
        "image = cv2.imread(data)\n",
        "print(detect(image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSUQbFj2-iAI",
        "outputId": "73bb4e78-7fd8-4f13-9515-999bbd30f16e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 682ms/step\n",
            "front\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Building"
      ],
      "metadata": {
        "id": "Jh7-h-M--qFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For Level"
      ],
      "metadata": {
        "id": "p54ds8yS-wa2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Importing The Model Building Libraries"
      ],
      "metadata": {
        "id": "9u_TRIYa-1fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "KZwx6mEV_RgH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Loading The Model"
      ],
      "metadata": {
        "id": "Ao0DAEBF_Xdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ibm project files/Car damage/level/training'\n",
        "valid_path = '/content/drive/MyDrive/ibm project files/Car damage/level/validation'"
      ],
      "metadata": {
        "id": "BSbO5gZh_ZTs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "8mO_MC58_d0h"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Adding Flatten Layer"
      ],
      "metadata": {
        "id": "MAixcmyX_kAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "wVITiJUV_qra"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob('/content/drive/MyDrive/ibm project files/Car damage/level/validation/*')"
      ],
      "metadata": {
        "id": "11wTtZP6_v3Y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHySWNEB_1Uy",
        "outputId": "ac8a7d65-f2ba-4f87-9c52-7645d0f5d29b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/ibm project files/Car damage/level/validation/02-moderate',\n",
              " '/content/drive/MyDrive/ibm project files/Car damage/level/validation/01-minor',\n",
              " '/content/drive/MyDrive/ibm project files/Car damage/level/validation/03-severe']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg16.output)"
      ],
      "metadata": {
        "id": "KdYys-77_453"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(folders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBKns23TAALa",
        "outputId": "01eca144-c5c6-4c88-fa00-277229ce2693"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Adding Output Layer"
      ],
      "metadata": {
        "id": "GAf1QBh3AF1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ],
      "metadata": {
        "id": "YZim5RMcAOpF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Creating A Model Object"
      ],
      "metadata": {
        "id": "P4hy8VslATJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=vgg16.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "SzJr9XxpAYWr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M8TPlA1AdFt",
        "outputId": "3a1610fc-86c1-4f1e-91dd-ae2225f81151"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 75267     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,789,955\n",
            "Trainable params: 75,267\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Configure The Learning Process"
      ],
      "metadata": {
        "id": "P1iyHYmRAgyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "b6pjBmcXAnHx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Train The Model"
      ],
      "metadata": {
        "id": "TaGOlBzgAu_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.1,zoom_range=0.1,horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "x2KfM2vYAzFK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPath = '/content/drive/MyDrive/ibm project files/Car damage/level/training'\n",
        "testPath = '/content/drive/MyDrive/ibm project files/Car damage/level/validation'"
      ],
      "metadata": {
        "id": "O1B1iL8oSjRL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e8d513-afae-44cb-d8a1-e4628e7f7b5d",
        "id": "grHUwO8pTQYk"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 979 images belonging to 3 classes.\n",
            "Found 171 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory(trainPath,target_size=(244,244),batch_size=10,class_mode='categorical')\n",
        "test_set = train_datagen.flow_from_directory(testPath,target_size=(244,244),batch_size=10,class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQzHXa8hTgtI",
        "outputId": "631c6e5b-b09d-4783-dddd-1bcf000882f8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'01-minor': 0, '02-moderate': 1, '03-severe': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit_generator(\n",
        "    training_set,\n",
        "    validation_data = test_set,\n",
        "    epochs = 25,\n",
        "    steps_per_epoch=979//10,\n",
        "    validation_steps = 171//10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4j3SZrcTxRX",
        "outputId": "b65010f1-4c2f-4e99-8fa6-2c6874fc60dc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "97/97 [==============================] - 634s 7s/step - loss: 1.2682 - accuracy: 0.5366 - val_loss: 0.8523 - val_accuracy: 0.6059\n",
            "Epoch 2/25\n",
            "97/97 [==============================] - 627s 6s/step - loss: 0.7518 - accuracy: 0.7100 - val_loss: 0.8500 - val_accuracy: 0.6412\n",
            "Epoch 3/25\n",
            "97/97 [==============================] - 628s 6s/step - loss: 0.5602 - accuracy: 0.7812 - val_loss: 1.2610 - val_accuracy: 0.5588\n",
            "Epoch 4/25\n",
            "97/97 [==============================] - 627s 6s/step - loss: 0.4048 - accuracy: 0.8400 - val_loss: 0.9745 - val_accuracy: 0.6471\n",
            "Epoch 5/25\n",
            "97/97 [==============================] - 627s 6s/step - loss: 0.3305 - accuracy: 0.8834 - val_loss: 1.1164 - val_accuracy: 0.6176\n",
            "Epoch 6/25\n",
            "97/97 [==============================] - 628s 6s/step - loss: 0.2707 - accuracy: 0.8968 - val_loss: 1.2373 - val_accuracy: 0.5824\n",
            "Epoch 7/25\n",
            "97/97 [==============================] - 626s 6s/step - loss: 0.2523 - accuracy: 0.9061 - val_loss: 1.1922 - val_accuracy: 0.6000\n",
            "Epoch 8/25\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.9556Epoch 9/25\n",
            "97/97 [==============================] - 627s 6s/step - loss: 0.1369 - accuracy: 0.9525 - val_loss: 1.7262 - val_accuracy: 0.6529\n",
            "Epoch 10/25\n",
            "97/97 [==============================] - 627s 6s/step - loss: 0.1285 - accuracy: 0.9536 - val_loss: 1.3090 - val_accuracy: 0.6412\n",
            "Epoch 11/25\n",
            "97/97 [==============================] - 627s 6s/step - loss: 0.0810 - accuracy: 0.9814 - val_loss: 1.1786 - val_accuracy: 0.6118\n",
            "Epoch 12/25\n",
            "97/97 [==============================] - 627s 6s/step - loss: 0.0674 - accuracy: 0.9835 - val_loss: 1.3367 - val_accuracy: 0.6118\n",
            "Epoch 13/25\n",
            "97/97 [==============================] - 626s 6s/step - loss: 0.0737 - accuracy: 0.9794 - val_loss: 1.3028 - val_accuracy: 0.6235\n",
            "Epoch 14/25\n",
            "97/97 [==============================] - 625s 6s/step - loss: 0.0531 - accuracy: 0.9876 - val_loss: 1.2366 - val_accuracy: 0.5882\n",
            "Epoch 15/25\n",
            "97/97 [==============================] - 626s 6s/step - loss: 0.0410 - accuracy: 0.9917 - val_loss: 1.2922 - val_accuracy: 0.6353\n",
            "Epoch 16/25\n",
            "97/97 [==============================] - 624s 6s/step - loss: 0.0292 - accuracy: 0.9979 - val_loss: 1.2133 - val_accuracy: 0.6059\n",
            "Epoch 17/25\n",
            "97/97 [==============================] - 624s 6s/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 1.2652 - val_accuracy: 0.6588\n",
            "Epoch 18/25\n",
            "97/97 [==============================] - 625s 6s/step - loss: 0.0302 - accuracy: 0.9979 - val_loss: 1.3260 - val_accuracy: 0.6294\n",
            "Epoch 19/25\n",
            "97/97 [==============================] - 625s 6s/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.1887 - val_accuracy: 0.6412\n",
            "Epoch 20/25\n",
            "97/97 [==============================] - 625s 6s/step - loss: 0.0185 - accuracy: 0.9990 - val_loss: 1.2564 - val_accuracy: 0.6118\n",
            "Epoch 21/25\n",
            "97/97 [==============================] - 624s 6s/step - loss: 0.0315 - accuracy: 0.9959 - val_loss: 1.2576 - val_accuracy: 0.6235\n",
            "Epoch 22/25\n",
            "97/97 [==============================] - 624s 6s/step - loss: 0.0271 - accuracy: 0.9969 - val_loss: 1.2825 - val_accuracy: 0.6059\n",
            "Epoch 23/25\n",
            "97/97 [==============================] - 625s 6s/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 1.2154 - val_accuracy: 0.6294\n",
            "Epoch 24/25\n",
            "97/97 [==============================] - 624s 6s/step - loss: 0.0505 - accuracy: 0.9835 - val_loss: 1.3384 - val_accuracy: 0.5824\n",
            "Epoch 25/25\n",
            "97/97 [==============================] - 624s 6s/step - loss: 0.0393 - accuracy: 0.9886 - val_loss: 1.2476 - val_accuracy: 0.6235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Save The Model"
      ],
      "metadata": {
        "id": "54BLY0viA679"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n"
      ],
      "metadata": {
        "id": "GQzrX9QvBAQU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/damage vehicle/Model/level.h5')"
      ],
      "metadata": {
        "id": "_w0VgplGUPa_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9. Test The Model"
      ],
      "metadata": {
        "id": "e8H1ytumBJm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "g1MG1OFuBLYQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/damage vehicle/Model/level.h5')"
      ],
      "metadata": {
        "id": "af5wigGHBP-P"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "  img = cv2.resize(frame,(224,224))\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if(np.max(img)>1):\n",
        "    img = img/255.0\n",
        "  img = np.array([img])\n",
        "  prediction = model.predict(img)\n",
        "  label = [\"minor\",\"moderate\",\"severe\"]\n",
        "  preds = label[np.argmax(prediction)]\n",
        "  return preds"
      ],
      "metadata": {
        "id": "U5YLof2ZBUPx"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RHith3OFBahh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"/content/drive/MyDrive/ibm project files/Car damage/level/validation/01-minor/0005.JPEG\"\n",
        "image = cv2.imread(data)\n",
        "print(detect(image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0nZW5_TBe68",
        "outputId": "645ee3a0-8b6c-403c-aa8a-2d6e457049d4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 706ms/step\n",
            "minor\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}